{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer,IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# from pyspark.ml.feature import IDF\n",
    "# from pyspark.ml.feature import DCT\n",
    "# from pyspark.ml.feature import PolynomialExpansion\n",
    "# from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml import Pipeline\n",
    "import itertools as it\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1. rename column names containing '.' (GS1-279B7.1, GS1-600G8.3 CAND1.11, HY.1)\n",
    "#      2. read csv sep = ',' for cpv final matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"VisualApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.24.50.199:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>VisualApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10e2bf390>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.executor.memory', '7g')\n",
    "#sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.context.SparkContext"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get all stored variables\n",
    "def list_dataframes():\n",
    "    from pyspark.sql import DataFrame\n",
    "    return [k for (k, v) in globals().items() if isinstance(v, DataFrame)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'botocore'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-051e2e88a861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'botocore'"
     ]
    }
   ],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def check(s3, bucket, key):\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket, Key=key)\n",
    "    except ClientError as e:\n",
    "        return int(e.response['Error']['Code']) != 404\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingMetrics(trainingSummary,printout=True):\n",
    "    # for multiclass, we can inspect metrics on a per-label basis\n",
    "#     print(\"False positive rate by label:\")\n",
    "#     for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "#         print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "#     print(\"True positive rate by label:\")\n",
    "#     for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "#         print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "#     print(\"Precision by label:\")\n",
    "#     for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "#         print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "#     print(\"Recall by label:\")\n",
    "#     for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "#         print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "    print(\"F-measure by label:\")\n",
    "    for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "        print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "    accuracy = trainingSummary.accuracy\n",
    "    falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "    truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "    fMeasure = trainingSummary.weightedFMeasure()\n",
    "    precision = trainingSummary.weightedPrecision\n",
    "    recall = trainingSummary.weightedRecall\n",
    "    if printout is True:\n",
    "        print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "          % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))\n",
    "    return {\"accuracy\": accuracy, \"fpr\": falsePositiveRate, \"tpr\": truePositiveRate, \"fmeasure\": fMeasure, \\\n",
    "            \"precision\": precision, \"recall\": recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data file\n",
    "mirna_path = 'gdc-emr0/mirna_filtered_matrix.csv'\n",
    "cpv_path = 'gdc-emr0/cpv_filtered_matrix.csv'\n",
    "mrna_path = 'gdc-emr0/mrna_filtered_matrix.csv'\n",
    "# read mirna\n",
    "df_mirna = spark.read.option(\"maxColumns\", 22400).csv(\n",
    "    mirna_path, header=True, sep = ',',mode=\"DROPMALFORMED\",inferSchema=True)\n",
    "# read cpv\n",
    "df_cpv = spark.read.option(\"maxColumns\", 22400).csv(\n",
    "    cpv_path, header=True, sep = ',',mode=\"DROPMALFORMED\",inferSchema=True)\n",
    "# # read mrna\n",
    "# df_mrna = spark.read.option(\"maxColumns\", 22400).csv(\n",
    "#     mrna_path, header=True, sep = ',',mode=\"DROPMALFORMED\",inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpv = df_cpv.toDF(*(c.replace('.', '_') for c in df_cpv.columns))\n",
    "# df_mrna = df_mrna.toDF(*(c.replace('.', '_') for c in df_mrna.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group columns by label, identifier and feature\n",
    "label_columns = ['sample_type', 'disease_type', 'primary_diagnosis']\n",
    "mirna_identifier_columns = ['sample_id','case_id']\n",
    "mirna_feature_columns = [x for x in df_mirna.columns if x not in (label_columns+mirna_identifier_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group columns by label, identifier and feature\n",
    "cpv_identifier_columns= ['_c0','sample_id','case_id']\n",
    "cpv_feature_columns = [x for x in df_cpv.columns if x not in (label_columns+cpv_identifier_columns)]\n",
    "df_cpv = df_cpv.withColumnRenamed(\"sample_type\", \"sample_type_cpv\").withColumnRenamed(\"disease_type\", \"disease_type_cpv\").withColumnRenamed(\"primary_diagnosis\",\"primary_diagnosis_cpv\").withColumnRenamed(\"case_id\", \"case_id_cpv\")\n",
    "cpv_label_columns = ['sample_type_cpv', 'disease_type_cpv', 'primary_diagnosis_cpv']\n",
    "cpv_identifier_columns=['_c0','sample_id','case_id_cpv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # group columns by label, identifier and feature\n",
    "# # cpv_label_columns = ['sample_type', 'disease_type', 'primary_diagnosis']\n",
    "# mrna_identifier_columns= ['_c0','sample_id','case_id']\n",
    "# mrna_feature_columns = [x for x in df_mrna.columns if x not in (label_columns+mrna_identifier_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features into (sparse) vectors\n",
    "# mirna\n",
    "assembler = VectorAssembler(inputCols=mirna_feature_columns, outputCol='features_mirna')\n",
    "df_mirna = assembler.transform(df_mirna)\n",
    "df_mirna=df_mirna.drop(*mirna_feature_columns)\n",
    "# eventually we should store/load from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpv\n",
    "assembler = VectorAssembler(inputCols=cpv_feature_columns, outputCol='features_cpv')\n",
    "df_cpv = assembler.transform(df_cpv)\n",
    "df_cpv = df_cpv.drop(*cpv_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cpv.join(df_mirna, on=['sample_id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parallelize() missing 1 required positional argument: 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-df39291dca70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mseriesX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# a series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# seriesY must have the same number of partitions and cardinality as seriesX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mseriesY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m555.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: parallelize() missing 1 required positional argument: 'c'"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "seriesX = SparkContext.parallelize([1.0, 2.0, 3.0, 3.0, 5.0])  # a series\n",
    "# seriesY must have the same number of partitions and cardinality as seriesX\n",
    "seriesY = SparkContext.parallelize([11.0, 22.0, 33.0, 33.0, 555.0])\n",
    "\n",
    "# # Compute the correlation using Pearson's method. Enter \"spearman\" for Spearman's method.\n",
    "# # If a method is not specified, Pearson's method will be used by default.\n",
    "# print(\"Correlation is: \" + str(Statistics.corr(seriesX, seriesY, method=\"pearson\")))\n",
    "\n",
    "# data = sc.parallelize(\n",
    "#     [np.array([1.0, 10.0, 100.0]), np.array([2.0, 20.0, 200.0]), np.array([5.0, 33.0, 366.0])]\n",
    "# )  # an RDD of Vectors\n",
    "\n",
    "# calculate the correlation matrix using Pearson's method. Use \"spearman\" for Spearman's method.\n",
    "# If a method is not specified, Pearson's method will be used by default.\n",
    "# df_mirna= Statistics.corr(df_mirna.rdd, method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.24.50.199:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>VisualApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10e2bf390>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string labels to numerical labels\n",
    "# keep track of the column names of numerical labels\n",
    "label_idx_columns = [s + '_idx' for s in cpv_label_columns]\n",
    "\n",
    "# declare indexers for 3 columns\n",
    "labelIndexer = [StringIndexer(inputCol=column, outputCol=column+'_idx',handleInvalid=\"error\",\n",
    "                              stringOrderType=\"frequencyDesc\") for column in cpv_label_columns ]\n",
    "# pipeline is needed to process a list of 3 labels\n",
    "pipeline = Pipeline(stages=labelIndexer)\n",
    "# transform 3 label columns from string to number catagoies \n",
    "df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# create dictionary containing 3 label lists\n",
    "label_dict = {c.name: c.metadata[\"ml_attr\"][\"vals\"]\n",
    "for c in df.schema.fields if c.name.endswith(\"_idx\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full-feature\n",
    "full_feature_columns=['features_mirna','features_cpv']\n",
    "assembler = VectorAssembler(inputCols=full_feature_columns, outputCol='full_features')\n",
    "df = assembler.transform(df)\n",
    "# df = df.drop(*cpv_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "mat = sc.parallelize(\n",
    "    [np.array([1.0, 10.0, 100.0]), np.array([2.0, 20.0, 200.0]), np.array([3.0, 30.0, 300.0])]\n",
    ")  # an RDD of Vectors\n",
    "\n",
    "# Compute column summary statistics.\n",
    "summary = Statistics.colStats(mat)\n",
    "print(summary.mean())  # a dense vector containing the mean value for each column\n",
    "print(summary.variance())  # column-wise variance\n",
    "print(summary.numNonzeros())  # number of nonzeros in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization \n",
    "scaler = StandardScaler(inputCol='full_features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
    "\n",
    "# # # Convert indexed labels back to original labels\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=label_dict['disease_type_cpv_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluators\n",
    "f1_evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol='disease_type_cpv_idx', metricName='f1')\n",
    "acc_evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol='disease_type_cpv_idx', metricName='accuracy')\n",
    "precision_evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol='disease_type_cpv_idx', metricName='weightedPrecision')\n",
    "recall_evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\",labelCol='disease_type_cpv_idx', metricName='weightedRecall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split \n",
    "Xtest,Xtrain = df.randomSplit([0.3, 0.7], seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_sample_id = Xtest.select('sample_id').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "stdmodelPath = 'full_std_model'\n",
    "    print(\"loading StandardScalar model...\")\n",
    "    stdmodel = StandardScalerModel.load(stdmodelPath)\n",
    "# if check(s3, 'gdc-emr0', stdmodelPath) == False:\n",
    "#     print(\"saving StandardScalar model...\")\n",
    "#     stdmodel = scaler.fit(Xtrain)\n",
    "#     stdmodel.save('s3://gdc-emr0/full_std_model')\n",
    "# else:\n",
    "#     from pyspark.ml.feature import StandardScalerModel\n",
    "#     print(\"loading StandardScalar model...\")\n",
    "#     stdmodel = StandardScalerModel.load(stdmodelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = stdmodel.transform(Xtrain)\n",
    "Xtest = stdmodel.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save\n",
    "# df.rdd.saveAsPickleFile(filename)\n",
    "# to load\n",
    "#pickleRdd = sc.pickleFile(filename).collect()\n",
    "# df2 = spark.createDataFrame(pickleRdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(cacheNodeIds=True, featuresCol='scaledFeatures',labelCol ='disease_type_cpv_idx', numTrees=1000,\\\n",
    "                           seed=seed)\n",
    "\n",
    "\n",
    "# # Hyperparameters to test\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.maxDepth, [5,7,9])\\\n",
    "            .build()\n",
    "\n",
    "# # K-fold cross validation \n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=f1_evaluator,\n",
    "                          numFolds=5,seed=seed)  # use 3+ folds in practice\n",
    "\n",
    "# # Put steps in a pipeline\n",
    "pipeline = Pipeline(stages=[crossval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "pipModel = pipeline.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = pipModel.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hyperparameters for best model\n",
    "cvModel = pipModel.stages[-1]\n",
    "bestParams = cvModel.extractParamMap()\n",
    "# print ('Best Param (regParam): ', bestModel._java_obj.getRegParam())\n",
    "bestModel = cvModel.bestModel\n",
    "feature_importance = bestModel.featureImportances\n",
    "num_trees = bestModel.getNumTrees\n",
    "tree_weights = bestModel.treeWeights\n",
    "trees =  bestModel.trees\n",
    "# # save model\n",
    "# bestModel.save('cpv1600_rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "modelPath = 'full_rf_model/data/_SUCCESS'\n",
    "if check(s3, 'gdc-emr0', stdmodelPath) == False:\n",
    "    print(\"saving Random Forest model...\")\n",
    "    bestModel.save('s3://gdc-emr0/full_rf_model')\n",
    "else:\n",
    "    print(modelPath+\" already exists...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=label_dict['disease_type_cpv_idx'])\n",
    "predictions = labelConverter.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_rd_df = pd.DataFrame(feature_importance, columns=['feature_importance'])\n",
    "# cpv_feature_columns+mirna_feature_columns\n",
    "from io import StringIO\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "feature_rd_df.to_csv(csv_buffer)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object('gdc-emr0', 'rf_feature_impt.csv').put(Body=csv_buffer.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
