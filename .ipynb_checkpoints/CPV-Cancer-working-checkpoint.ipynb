{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark as spark\n",
    "from pyspark.ml.feature import StringIndexer,IndexToString\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "# from pyspark.ml.feature import IDF\n",
    "# from pyspark.ml.feature import DCT\n",
    "# from pyspark.ml.feature import PolynomialExpansion\n",
    "# from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.ml import Pipeline\n",
    "import itertools as it\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1. rename column names containing '.' (GS1-279B7.1, GS1-600G8.3 CAND1.11, HY.1)\n",
    "#      2. read csv sep = ',' for cpv final matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SimpleApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.115:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SimpleApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11db71d68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "#sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get all stored variables\n",
    "def list_dataframes():\n",
    "    from pyspark.sql import DataFrame\n",
    "    return [k for (k, v) in globals().items() if isinstance(v, DataFrame)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data file\n",
    "path = 'CPV/cpv_final_matrix_test.csv'\n",
    "df = spark.read.option(\"maxColumns\", 22400).csv(\n",
    "    path, header=True, sep = '\\t',mode=\"DROPMALFORMED\",inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group columns by label, identifier and feature\n",
    "label_columns = ['sample_type', 'disease_type', 'primary_diagnosis']\n",
    "identifier_columns = ['_c0','sample_id','case_id']\n",
    "feature_columns = [x for x in df.columns if x not in (label_columns+identifier_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features into (sparse) vectors\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "df = assembler.transform(df)\n",
    "df=df.drop(*feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string labels to numerical labels\n",
    "# keep track of the column names of numerical labels\n",
    "label_idx_columns = [s + '_idx' for s in label_columns]\n",
    "\n",
    "# declare indexers for 3 columns\n",
    "labelIndexer = [StringIndexer(inputCol=column, outputCol=column+'_idx',handleInvalid=\"error\",\n",
    "                              stringOrderType=\"frequencyDesc\") for column in label_columns ]\n",
    "# pipeline is needed to process a list of 3 labels\n",
    "pipeline = Pipeline(stages=labelIndexer)\n",
    "# transform 3 label columns from string to number catagoies \n",
    "df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# create dictionary containing 3 label lists\n",
    "label_dict = {c.name: c.metadata[\"ml_attr\"][\"vals\"]\n",
    "for c in df.schema.fields if c.name.endswith(\"_idx\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Logistic Regression - cancer/no-cancer classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split\n",
    "Xtest,Xtrain = df.randomSplit([0.3, 0.7], seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Standardization \n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
    "\n",
    "# Logistic Regression model \n",
    "lr = LogisticRegression(aggregationDepth= 3,maxIter=100, regParam=0.4, elasticNetParam=0.5,\n",
    "                        featuresCol='scaledFeatures',labelCol ='sample_type_idx',\n",
    "                       family='binomial',tol=1e-06)\n",
    "\n",
    "# Hyperparameters to test\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1,0.4])\\\n",
    "            .build()\n",
    "\n",
    "# K-fold cross validation \n",
    "crossval = CrossValidator(estimator=lr,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"sample_type_idx\",metricName=\"areaUnderROC\"),\n",
    "                          numFolds=2,seed=seed)  # use 3+ folds in practice\n",
    "\n",
    "# Put steps in a pipeline\n",
    "pipeline = Pipeline(stages=[scaler, crossval])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "pipModel = pipeline.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-54c26411b04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get hyperparameters for best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcvModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbestParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractParamMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbestModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbestModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcoeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipModel' is not defined"
     ]
    }
   ],
   "source": [
    "# get hyperparameters for best model\n",
    "cvModel = pipModel.stages[-1]\n",
    "bestParams = cvModel.extractParamMap()\n",
    "# print ('Best Param (regParam): ', bestModel._java_obj.getRegParam())\n",
    "bestModel = cvModel.bestModel\n",
    "coeff = bestModel.coefficients\n",
    "intercept = bestModel.intercept\n",
    "# save model\n",
    "# bestModel.save('cpv1600_logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = pipModel.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=label_dict['sample_type_idx'])\n",
    "predictions = labelConverter.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851932584269663\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"sample_type_idx\",metricName=\"areaUnderROC\")\n",
    "roc = evaluator.evaluate(predictions)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, sample_id: string, sample_type: string, disease_type: string, primary_diagnosis: string, case_id: string, features: vector, sample_type_idx: double, disease_type_idx: double, primary_diagnosis_idx: double, scaledFeatures: vector, rawPrediction: vector, probability: vector, prediction: double, predictedLabel: string]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions.select(\"sample_type\",\"predictedLabel\",\"sample_type_idx\",\"prediction\",\"rawPrediction\",\"probability\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test/train split\n",
    "Xtest,Xtrain = df.randomSplit([0.3, 0.7], seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "# Random Forest Classifier\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaledFeatures', withStd=True, withMean=True)\n",
    "\n",
    "rf = RandomForestClassifier(cacheNodeIds=True, featuresCol='scaledFeatures',labelCol ='sample_type_idx', numTrees=200,\\\n",
    "                           seed=seed,)\n",
    "\n",
    "\n",
    "# # Hyperparameters to test\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.maxDepth, [10,20])\\\n",
    "            .build()\n",
    "\n",
    "# # K-fold cross validation \n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"sample_type_idx\",metricName=\"areaUnderROC\"),\n",
    "                          numFolds=2,seed=seed)  # use 3+ folds in practice\n",
    "\n",
    "# # Put steps in a pipeline\n",
    "pipeline = Pipeline(stages=[scaler, crossval])\n",
    "\n",
    "\n",
    "# # Convert indexed labels back to original labels\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=label_dict['sample_type_idx'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "pipModel = pipeline.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hyperparameters for best model\n",
    "cvModel = pipModel.stages[-1]\n",
    "bestParams = cvModel.extractParamMap()\n",
    "# print ('Best Param (regParam): ', bestModel._java_obj.getRegParam())\n",
    "bestModel = cvModel.bestModel\n",
    "feature_importance = bestModel.featureImportances\n",
    "tree_weights = bestModel.treeWeights\n",
    "trees =  bestModel.trees\n",
    "# save model\n",
    "# bestModel.save('cpv1600_logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = pipModel.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=label_dict['sample_type_idx'])\n",
    "predictions = labelConverter.transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8918651685393256\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"sample_type_idx\",metricName=\"areaUnderROC\")\n",
    "roc = evaluator.evaluate(predictions)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection by top percentile\n",
    "p_selector = ChiSqSelector(selectorType = 'percentile', percentile=0.1, outputCol=\"percentFeatures\",featuresCol=\"features\",labelCol=\"sample_type_idx\")\n",
    "p_selector_model = p_selector.fit(XyTrain)\n",
    "\n",
    "# feature seleciton by false-positive-rate threshold\n",
    "f_selector = ChiSqSelector(selectorType = 'fpr', fpr=0.2, outputCol=\"fprFeatures\",featuresCol=\"features\",labelCol=\"sample_type_idx\")\n",
    "f_selector_model = f_selector.fit(XyTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percent Selecter:\", p_selector.getNumTopFeatures())\n",
    "print(\"FPR Selecter:\", f_selector.getNumTopFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(p_selector_model.selectedFeatures)&set(f_selector_model.selectedFeatures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(fpath,fname,obj):\n",
    "    # selector saver \n",
    "    fullpath = fpath + '/'+ fname\n",
    "    obj.save(fullpath)\n",
    "\n",
    "# def load(fpath):\n",
    "#     # selector loader\n",
    "#     loadedSelector = ChiSqSelector.load(chiSqSelectorPath)\n",
    "#     loadedSelector.getNumTopFeatures() == selector.getNumTopFeatures()\n",
    "#     # model loader\n",
    "#     loadedModel = ChiSqSelectorModel.load(modelPath)\n",
    "#     loadedModel.selectedFeatures == model.selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "save(cwd,'cpv_toy_10percent_chi_selector',p_selector)\n",
    "save(cwd,'cpv_toy_10percent_chi_model',p_selector_model)\n",
    "save(cwd,'cpv_toy_2fpr_chi_selector',f_selector)\n",
    "save(cwd,'cpv_toy_2fpr_model',f_selector_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regerssion for Cancer/No Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']).select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)\n",
    "print(\"setting model to best threshold:\"+ str(bestThreshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression for Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=1000, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\",featuresCol='scaledFeatures',labelCol ='disease_type_idx')\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(XyTrain_disease)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']).select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)\n",
    "print(\"setting model to best threshold:\"+ str(bestThreshold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
